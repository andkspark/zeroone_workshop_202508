{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Start Langchain with Gemini  \n",
        "제작 : 박광석(모두의연구소, https://www.linkedin.com/in/andkspark)   \n",
        "  \n",
        "#### 해당 노트는 Langchain을 처음 접하시는 분들을 위한 튜토리얼입니다.  \n",
        "참고 :\n",
        "https://python.langchain.com/docs/get_started/introduction  \n",
        "https://python.langchain.com/docs/integrations/llms/google_ai/  \n",
        "YouTube <모두의AI>  \n",
        "인프런 <모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 2 - 랭체인(LangChain)으로 나만의 ChatGPT 만들기>\n"
      ],
      "metadata": {
        "id": "HFMBYK2SwI68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_API_KEY ="
      ],
      "metadata": {
        "id": "5QZZobfdyUYR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0 : 설치와 준비  \n",
        "Langchain 설치 및 Gemini API 키를 등록하도록 합니다.  "
      ],
      "metadata": {
        "id": "drDsT9tbxZZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDlkZu50yHxQ",
        "outputId": "317819c9-5d9f-4769-93e0-a986b97e188a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s_Q-g7IgwHGT",
        "outputId": "ad93c390-08ce-4f90-b718-b1657a0f2d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "af4b06cd06c94d6da47b9928f1207047"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = YOUR_API_KEY"
      ],
      "metadata": {
        "id": "On8wrXDKwIWE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 : LLM 사용해보기  \n",
        "굉장히 간단하게 LLM을 사용할 수 있습니다!  \n",
        "llm을 정의한 후, 답변을 얻기 위해, llm.invoke()를 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "boezOrKC4wEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#랭체인의 구글Api를 사용합니다\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\", temperature=0.0, google_api_key = YOUR_API_KEY,max_output_tokens = 200)\n",
        "\n",
        "request = llm.invoke(\"파이썬에 대해 설명해줘\")\n",
        "print(request)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6wvjjbp0jMz",
        "outputId": "0eb08436-6c92-4451-a375-7a6b2a223e22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='파이썬(Python)은 고급 프로그래밍 언어로, **읽기 쉽고 배우기 쉬운 문법**을 특징으로 합니다.  다양한 분야에서 사용되며, 초보자부터 전문가까지 폭넓게 사용하는 인기 있는 언어입니다.\\n\\n**주요 특징:**\\n\\n* **인터프리터 언어:** 컴파일 과정 없이 코드를 한 줄씩 실행합니다. 이로 인해 개발 속도가 빠르고 디버깅이 용이합니다.  하지만 컴파일 언어보다 실행 속도는 느릴 수 있습니다.\\n* **동적 타이핑:** 변수의 자료형을 명시적으로 선언할 필요가 없습니다.  런타임 시에 자료형이 결정됩니다.  유연성을 제공하지만, 런타임 에러 발생 가능성도 높아집니다' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'MAX_TOKENS', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run--5db5800e-2f4d-4adb-b871-1d8f7c5dd2e5-0' usage_metadata={'input_tokens': 8, 'output_tokens': 200, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query의 결과에는 답변 뿐만이 아닌, 메타데이터와 실행id가 함께 리턴됩니다.  \n",
        "답변을 나타내는 content 키만 출력하도록 해보겠습니다.  "
      ],
      "metadata": {
        "id": "x2uSFtWM8zam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXhUGGr78fuL",
        "outputId": "2f356b42-53d8-435f-8d94-038ec5914a55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파이썬(Python)은 고급 프로그래밍 언어로, **읽기 쉽고 배우기 쉬운 문법**을 특징으로 합니다.  다양한 분야에서 사용되며, 초보자부터 전문가까지 폭넓게 사용하는 인기 있는 언어입니다.\n",
            "\n",
            "**주요 특징:**\n",
            "\n",
            "* **인터프리터 언어:** 컴파일 과정 없이 코드를 한 줄씩 실행합니다. 이로 인해 개발 속도가 빠르고 디버깅이 용이합니다.  하지만 컴파일 언어보다 실행 속도는 느릴 수 있습니다.\n",
            "* **동적 타이핑:** 변수의 자료형을 명시적으로 선언할 필요가 없습니다.  런타임 시에 자료형이 결정됩니다.  유연성을 제공하지만, 런타임 에러 발생 가능성도 높아집니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2 : schema 사용해보기  \n",
        "\n",
        "Schema는 agent와 원활하게 작업할 수 있도록 돕는 메세지 추상화 개념입니다.  \n",
        "  \n",
        "SystemMessage : LLM에 역할을 부여할 수 있습니다. 대화의 맥락을 부여하며, 행동 설정 혹은 제약을 위해 사용할 수 있습니다.  \n",
        "HumanMessage : 사용자가 LLM에게 대화 혹은 요청을 위해 보내는 메세지입니다.  \n",
        "AIMessage : AI assistent가 제공하는 메세지, 즉 대답입니다.  \n",
        "이외에도 function call 로부터 주어진 message인 FunctionMessage가 있습니다.\n"
      ],
      "metadata": {
        "id": "DBjE6UTYyh92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
      ],
      "metadata": {
        "id": "dt9bsaR8yfuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that translates English to Korean.\"),\n",
        "    HumanMessage(content=\"Translate this sentence: I love programming.\"),\n",
        "]\n",
        "\n",
        "# 현재 SystemMessages 가 지원되지 않아, convert_system_message_to_human=True 의 option을 llm 생성시에 사용해야 합니다\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGUxYuiq0moH",
        "outputId": "caae0c38-c975-41f4-87fd-238662691080"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나는 프로그래밍을 좋아해요. (naneun peurogeuramming-eul joa haeyo)\n",
            "\n",
            "This is a polite and common way to say it.  You could also say:\n",
            "\n",
            "나는 프로그래밍이 좋아요. (naneun peurogeuramming-i joa haeyo) - This is also polite, but slightly different in nuance.  It emphasizes the *act* of programming itself being enjoyable rather than the act of *doing* programming.  The difference is subtle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqWRBbSQ2xaC",
        "outputId": "1dbb3995-c05f-43b3-dfc8-6db90d9fc12b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='나는 프로그래밍을 좋아해요. (naneun peurogeuramming-eul joa haeyo)\\n\\nThis is a polite and common way to say it.  You could also say:\\n\\n나는 프로그래밍이 좋아요. (naneun peurogeuramming-i joa haeyo) - This is also polite, but slightly different in nuance.  It emphasizes the *act* of programming itself being enjoyable rather than the act of *doing* programming.  The difference is subtle.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--509f7590-3e97-4642-b6f7-f99b3a060b33-0', usage_metadata={'input_tokens': 19, 'output_tokens': 114, 'total_tokens': 133, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI의 답변은 AIMessage로 분류되어 있습니다."
      ],
      "metadata": {
        "id": "1hvPSu8a4ndo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3 : Prompt Templete 사용해보기  \n",
        "모델에 입력하는 prompt를 규격화하여 효율적으로 LLM을 사용할 수 있게 하는 모듈입니다.  \n",
        "  \n",
        "ex) \"파란색 셔츠\" 와 잘 어울리는 \"바지\"를 추천해줘!   \n",
        "ex) \"흰 티셔츠\" 와 잘 어울리는  \"모자\"를 추천해줘!  \n",
        "  \n",
        "이렇게 예시의 반복되는 부분을 엔지니어링 할 수 있습니다.  \n",
        "\n",
        "    \n",
        "PromptTemplete : 일반적인 프롬프트 템플릿 생성 시 사용합니다.  \n",
        "{ }로 묶인 부분을 변수로 활용합니다  \n"
      ],
      "metadata": {
        "id": "4KF-PDQe5RGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"{meat}를 맛있게 만드는 좋은 방법은?\")\n",
        "prompt.format(meat=\"닭고기\")"
      ],
      "metadata": {
        "id": "1B56QgK_4mar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e2e774d-88f4-47e6-86da-1f8464edb056"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'닭고기를 맛있게 만드는 좋은 방법은?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatPromptTemplete : 채팅 LLM 특화, 위의 schema처럼 역할을 나누어 사용하도록 입력할 수 있습니다.  "
      ],
      "metadata": {
        "id": "eR_ZSuyODGq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "templete = \"당신은 최고의 번역가입니다 {input_language}를 {output_language}로 번역해서 알려주세요\"\n",
        "human_templete = \"{text}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", templete),\n",
        "    (\"human\", human_templete),\n",
        "])\n",
        "\n",
        "format_message = chat_prompt.format_messages(input_language=\"English\", output_language = \"Korean\", text = \"I love pizza\")"
      ],
      "metadata": {
        "id": "DbDQw0SN4ml_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7QKFauJUyGQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 Format한 prompt를 LLM에 넣어 결과를 확인할 수 있습니다.  "
      ],
      "metadata": {
        "id": "y_6c_kEQDtz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(format_message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r34sImStDsRR",
        "outputId": "5c68551b-2c19-499e-9552-9fbb12cc4937"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "피자를 정말 좋아해요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4 : Parser 사용해보기  \n",
        "\n",
        "Parser는 llm에서 response로 넘어가는 text를 원하는 형태로 파싱하도록 도와주는 모듈입니다  "
      ],
      "metadata": {
        "id": "NrjsjkmCTpro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "  #baseOutputParser를 상속받음\n",
        "  #comma를 기준으로 문자열을 나누어주는 parser를 사용해보겠습니다\n",
        "    def parse(self, text: str) -> list:\n",
        "        return text.strip().split(\", \")\n",
        "\n",
        "CommaSeparatedListOutputParser().parse(\"hello , Hyundai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iucfXhzyECSn",
        "outputId": "6c780a42-a00f-4835-a1c6-eb148081d04b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello ', 'Hyundai']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step5 : Chain 사용하여 결합해보기  \n",
        "Chain 은 Langchain의 핵심 기능으로, 위의 과정들을 묶어 한번에 수행할 수 있도록 합니다.  \n",
        "다른 langchain의 구성끼리,  | 기호를 사용하여 연결할 수 있습니다."
      ],
      "metadata": {
        "id": "iS19a9iMUoRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "templete = \"\"\"당신은 쉼표로 구분된 목록을 생성하는 유용한 조수입니다. \\\n",
        "사용자가 카테고리를 전달하면 해당 카테고리에 속하는 5개의 객체를 쉼표로 구분된 목록으로 생성합니다. \\\n",
        "오직 쉼표로 구분된 목록만 반환하고 그 이상은 반환하지 마세요.\"\"\"\n",
        "\n",
        "human_templete = \"{text}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", templete),\n",
        "    (\"human\", human_templete),\n",
        "])"
      ],
      "metadata": {
        "id": "B0L6IOMOVw_0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 정의한 프롬프트 탬플릿, LLM, Parser를 결합해보겠습니다."
      ],
      "metadata": {
        "id": "5dPkyB6tV9YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | CommaSeparatedListOutputParser()\n",
        "response = chain.invoke (\"text : 색깔\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLYilSWBV66o",
        "outputId": "e9435b44-300c-494d-f584-49ec2f426427"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['빨강', '파랑', '초록', '노랑', '보라']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수고하셨습니다!  "
      ],
      "metadata": {
        "id": "Gp5fXbLd0UE3"
      }
    }
  ]
}