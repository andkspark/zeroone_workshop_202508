{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgWF2j10oSEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aedb9394-3ef2-4b80-f2ec-5050deac3d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.74)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=752f353ecaa0e224fc1a1916671cae3719bbe45f6a42ff75d4e6d4c63759aba2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/11/dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf, filetype, pypdfium2, ormsgpack, mypy-extensions, marshmallow, typing-inspect, pdfminer.six, langgraph-sdk, dataclasses-json, pdfplumber, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 fpdf-1.7.2 google-ai-generativelanguage-0.6.18 langchain-community-0.3.27 langchain-experimental-0.3.4 langchain-google-genai-2.1.9 langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.3 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "62a689bd197e4d87b25ad9a9b80e2018"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain-google-genai langchain-core langchain-community langchain-experimental fpdf pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jLETHnXnKBh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain.schema import AIMessage\n",
        "from typing import Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.agent_toolkits import FileManagementToolkit\n",
        "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
        "from pydantic import BaseModel, Field\n",
        "from fpdf import FPDF\n",
        "import random\n",
        "import pdfplumber\n",
        "import os\n",
        "import requests\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report Agent  \n",
        "LLM의 도움으로 보고서를 작성하는 에이전트를 만들어봅시다!  \n",
        "LLM이 검색한 정보를 바탕으로 보고서를 자동 구성하여, PDF파일로 저장하거나 삭제하는 등 관리할 수 있습니다.  \n",
        "  \n",
        "여기서는 부분적으로 tavily를 사용합니다.  \n",
        "Tavily는 웹에서 정보를 찾아 깔끔히 정리해 주는 검색 API로, AI/챗봇이 쓰기 좋고, 한 번 요청하면 검색→내용 추출→요약/정리→출처 링크까지 묶어주기 때문에 문서 생성 작업과 궁합이 잘 맞습니다. 특히 Langchain과의 호환성이 뛰어납니다.  "
      ],
      "metadata": {
        "id": "HQIBG7hgFW9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtLQpBZQIHsa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "google_api_key = \"\" # @param {\"type\":\"string\"}\n",
        "tavily_api_key = \"\" # @param {\"type\":\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8azdfq-l-ps"
      },
      "outputs": [],
      "source": [
        "os.environ[\"google_api_key\"] = google_api_key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report Agent  \n",
        "LLM"
      ],
      "metadata": {
        "id": "f-mPZh6zHMhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 상태 정의\n",
        "\n",
        "class State(TypedDict):\n",
        "    # 상태를 정의해주세요."
      ],
      "metadata": {
        "id": "yadBl2tBzziJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-CNSwr0qnsi"
      },
      "outputs": [],
      "source": [
        "# LLM 정의\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
        "#                              temperature=0,\n",
        "#                              convert_system_message_to_human=True)\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
        "#                              temperature=0,\n",
        "#                              convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNMa89_7nKBm"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def read_pdf(file_path: str):\n",
        "    \"\"\"\n",
        "    PDF 파일에서 텍스트를 추출하는 도구입니다.\n",
        "    표 형식 또는 일반 텍스트가 포함된 PDF를 읽고 문자열로 반환합니다.\n",
        "\n",
        "    file_path 예시: './report.pdf'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        return text.strip() if text.strip() else \"❌ PDF에서 텍스트를 추출할 수 없습니다.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ PDF 읽기 오류: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqkLXOw6nKBn"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def write_pdf(content: str, filename: str = \"output.pdf\", summary: bool =True):\n",
        "    \"\"\"\n",
        "    텍스트를 PDF 파일로 저장하는 도구입니다.\n",
        "    PDF형태의 문서로 만들어야할 때 이 도구를 사용하세요.\n",
        "    \"\"\"\n",
        "\n",
        "    if summary:\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "                당신은 보고서를 작성하는 어시스턴트입니다. 당신에겐 문서 모음이 제공되고 이를 잘 분석하여 보고서를 작성하여야 합니다.\n",
        "                아래의 content는 문서 모음입니다. 문서의 제목, 본문을 잘 판단하고 정리하여 요약합니다.\n",
        "                항상 구조화된 출력을 제공하세요.\n",
        "                항상 마지막엔 인사이트도 첨부합니다.\n",
        "\n",
        "                content : {content}\n",
        "                \"\"\")\n",
        "\n",
        "        chain = prompt | llm\n",
        "\n",
        "        content = chain.invoke({\"content\":content}).content\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    font_url = \"https://github.com/google/fonts/raw/main/ofl/notosanskr/NotoSansKR%5Bwght%5D.ttf\"\n",
        "    font_path = \"./fonts/NotoSansKR.ttf\"\n",
        "\n",
        "    try:\n",
        "        os.mkdir(\"./fonts/\")\n",
        "        response = requests.get(font_url)\n",
        "        with open(font_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    font_path = \"./fonts/NotoSansKR.ttf\"\n",
        "\n",
        "    try:\n",
        "        pdf.add_font(\"NotoSans\", \"\", font_path, uni=True)\n",
        "        pdf.set_font(\"NotoSans\", size=12)\n",
        "    except:\n",
        "        raise ValueError(\"한글 폰트를 등록할 수 없습니다.\")\n",
        "\n",
        "    for line in content.split(\"\\n\"):\n",
        "        pdf.multi_cell(0, 10, line)\n",
        "    pdf.output(f\"./{filename}\")\n",
        "\n",
        "    return f\"{filename} 저장 완료\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKMUZEXPIHsc"
      },
      "outputs": [],
      "source": [
        "# 툴 정의\n",
        "# TavilySearchResults : 웹 검색 도구\n",
        "# PythonAstREPLTool : 파이썬 코드 실행 도구\n",
        "# write_pdf : pdf 생성 도구\n",
        "# read_pdf : pdf 읽기 도구\n",
        "# file_delete : 파일 삭제 도구\n",
        "# list_directory : 파일 목록 읽기 도구\n",
        "\n",
        "tools = [TavilySearchResults(max_results=10), PythonAstREPLTool(), write_pdf, read_pdf, *FileManagementToolkit(\n",
        "                                                                            selected_tools=[\"file_delete\",\"list_directory\"]).get_tools()]\n",
        "search_tool, code_tool, write_tool, read_tool, delete_tool, listdir_tool= tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uOvOZf3nKBn"
      },
      "outputs": [],
      "source": [
        "# LLM에게 도구 할당\n",
        "\n",
        "llm_with_tools = # LLM에게 도구를 할당해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrMAISv-nKBo"
      },
      "outputs": [],
      "source": [
        "# 단기 기억(history)으로 추출 함수\n",
        "\n",
        "def shorterm_memory(state:State):\n",
        "\n",
        "    if len(state[\"messages\"]) # ?:\n",
        "        # 원하는 길이만큼 단기기억을 설정해보세요.\n",
        "    elif len(state[\"messages\"]) == 1:\n",
        "        history = \"\"\n",
        "    else:\n",
        "        history = state[\"messages\"][:-1]\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsqpQmxknKBo"
      },
      "outputs": [],
      "source": [
        "class HistoryChecker(BaseModel):\n",
        "    \"\"\"\n",
        "    이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "    답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    yes_no : Literal[\"yes\", \"no\"] = Field(..., description=\"\"\"Use your previous conversation history to determine if you can answer your questions.\n",
        "    Return \"yes\" if you can answer, \"no\" if you can't answer.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SsCloETnKBp"
      },
      "outputs": [],
      "source": [
        "# 히스토리 기반 답변 분기를 위한 함수 설정\n",
        "\n",
        "def history_check(state:State):\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "                답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    chain = prompt | history_checker\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    result = chain.invoke({\"history\":history,\n",
        "                            \"query\":state[\"query\"]})\n",
        "\n",
        "    return result.yes_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDAlnV3dnKBp"
      },
      "outputs": [],
      "source": [
        "# LLM의 응답을 HistoryChecker 클래스 구조에 맞춰 파싱하도록 설정\n",
        "\n",
        "history_checker = llm.with_structured_output(HistoryChecker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx8dfRdlnKBp"
      },
      "outputs": [],
      "source": [
        "# 기억 기반 답변 노드\n",
        "\n",
        "def memory_chat(state:State):\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변하세요.\n",
        "                아래 대화 기록을 첨부합니다.\n",
        "                대화 기록을 통해 답변이 어렵다면 내부 지식을 참조하세요.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    result = chain.invoke({\"history\":history,\n",
        "                           \"query\":state[\"query\"]})\n",
        "\n",
        "    if len(state[\"tool_call\"]) == 0:\n",
        "        return # \"answer\"는 result.content, \"messages\"는 result, \"tool_call\"은 \"사용된 기록 없음\" 으로 설정하여 상태를 업데이트 합니다.\n",
        "\n",
        "    else:\n",
        "        return # \"answer\"는 result.content, \"messages\"는 result로 상태를 업데이트합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기억 기반 답변 분기 노드\n",
        "\n",
        "def history_node(state:State):\n",
        "    if len(state[\"messages\"]) == 1:\n",
        "        return {\"answer\":\"답변 없음\",\n",
        "                \"tool_call\":\"사용된 도구 없음\"}\n",
        "    else:\n",
        "        return state"
      ],
      "metadata": {
        "id": "wJrrmgGr8_my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVxNiGN0nKBq"
      },
      "outputs": [],
      "source": [
        "# 도구 선택 노드\n",
        "\n",
        "def select(\n",
        "    state: State,\n",
        "):\n",
        "\n",
        "\n",
        "    # 프롬프트를 구성해주세요.\n",
        "    # 도구를 적절히 선택할 수 있도록 하여야합니다.\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                최근 사용한 도구 : {tool_name}\n",
        "\n",
        "                정답 : {answer}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    # 체인을 구성해주세요.\n",
        "    chain =\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    # 체인을 작동시켜주세요\n",
        "    result =\n",
        "\n",
        "    if hasattr(result, \"tool_calls\") and len(result.tool_calls) > 0:\n",
        "        tool_calls = result.tool_calls\n",
        "\n",
        "        return {\"messages\": result,\n",
        "                \"tool_call\":tool_calls}\n",
        "    else:\n",
        "        return {\"messages\":AIMessage(content=f\"\"\"도구를 선택하지 못했습니다. 적절한 도구를 재선택하세요.\n",
        "                                        \"\"\"),\n",
        "                                    \"tool_call\":\"선택된 도구 없음\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s0RyEfnKBq"
      },
      "outputs": [],
      "source": [
        "# 도구 실행 노드\n",
        "\n",
        "tool_node = # ToolNode에 도구를 부여하여 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD-vMnQenKBq"
      },
      "outputs": [],
      "source": [
        "class AnswerChecker(BaseModel):\n",
        "    \"\"\"\n",
        "    정답 분류기입니다.\n",
        "\n",
        "    정답이 질문을 해결했는지 여부를 판단합니다.\n",
        "    질문을 해결하지 못했을 시 해결될 때까지 도구를 이용합니다.\n",
        "\n",
        "    질문을 해결했다면 \"end\", 해결하지 못했다면 \"tool\"을 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    end : Literal[\"end\", \"tool\"] = Field(..., description=\"\"\"You are the answer sorter.\n",
        "\n",
        "                                                                Determine if the correct answer has solved the question.\n",
        "                                                                If the question is not resolved, use the tool until it is resolved.\n",
        "\n",
        "                                                                Return \"end\" if you solved the question, or \"tool\" if you didn't.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51lPyxhdnKBr"
      },
      "outputs": [],
      "source": [
        "# LLM의 응답을 AnswerChecker 클래스 구조에 맞춰 파싱하도록 설정\n",
        "\n",
        "answer_checker = # LLM이 구조화된 답변을 할 수 있도록 설정해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyZTkR8fnKBr"
      },
      "outputs": [],
      "source": [
        "# 답변 확인 노드\n",
        "\n",
        "def response(state:State):\n",
        "\n",
        "    return {\"answer\":state[\"messages\"][-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBV4ASvjnKBr"
      },
      "outputs": [],
      "source": [
        "# 답변 완성 판단 분기 함수\n",
        "\n",
        "def answer_check(state:State):\n",
        "\n",
        "    # 프롬프트를 구성해주세요.\n",
        "    # 질문이 해결됐는지 잘 판단할 수 있는 프롬프트를 만들어야 합니다.\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "    History : {history}\n",
        "\n",
        "    정답 : {answer}\n",
        "\n",
        "    질문 : {query}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = # 체인을 구성해주세요.\n",
        "\n",
        "    history = # 단기기억을 가져오세요.\n",
        "\n",
        "    result = # 체인을 작동시켜주세요.\n",
        "\n",
        "    return result.end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50EDu4mOnKBr"
      },
      "outputs": [],
      "source": [
        "# 그래프 정의\n",
        "\n",
        "graph_builder = # 그래프를 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDdqjxeNnKBr"
      },
      "outputs": [],
      "source": [
        "# 노드 및 엣지 정의\n",
        "\n",
        "# 로직을 잘 보고 노드와 엣지를 구성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Z71CK8nKBr"
      },
      "outputs": [],
      "source": [
        "# 메모리 설정 및 그래프 컴파일\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ2jWtlinKBs"
      },
      "outputs": [],
      "source": [
        "# 그래프 시각화\n",
        "# 가끔 \"ReadTimeout: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\"라는 에러가 발생\n",
        "# 시간 초과로 그래프 생성에 실패했다는 메시지일뿐 기능과는 관계없으니 진행해도 괜찮습니다.\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWcfKPoOnKBr"
      },
      "outputs": [],
      "source": [
        "# config 재생성 노드, config의 재사용은 고려되지 않음. 재사용한다면 변수에 할당하여 사용할 것\n",
        "\n",
        "def reset_config(limit=20):\n",
        "\n",
        "    thread_id=random.randint(1,999999)\n",
        "\n",
        "    config = RunnableConfig(recursion_limit=limit, configurable={\"thread_id\": thread_id})\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07_bBQgHnKBs"
      },
      "outputs": [],
      "source": [
        "# 출력 함수 정의\n",
        "# mode = \"values\" : 상태의 키, 값의 형태로 반환\n",
        "# mode = \"updates\" : 업데이트되는 값만 반환\n",
        "\n",
        "def streaming(query, config, mode=\"values\"):\n",
        "\n",
        "    result = graph.stream({\"messages\":(\"user\", query),\n",
        "                         \"query\":query}, config=config, stream_mode=mode)\n",
        "\n",
        "    if mode == \"values\":\n",
        "        for step in result:\n",
        "            for k, v in step.items():\n",
        "                if k == \"messages\":\n",
        "                    v[-1].pretty_print()\n",
        "    elif mode == \"updates\":\n",
        "        for step in result:\n",
        "            for k,v in step.items():\n",
        "                print(f\"\\n\\n=== {k} ===\\n\\n\")\n",
        "                print(v)\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI6E1DvhnKBs"
      },
      "outputs": [],
      "source": [
        "config = reset_config()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에이전트에게 자유롭게 질문해주세요."
      ],
      "metadata": {
        "id": "A_mJWtfCkN9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Modulabs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}